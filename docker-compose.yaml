services:
  airflow:
    image: apache/airflow:2.9.3-python3.11
    container_name: data_eng_task_airflow
    restart: always

    environment:
      # Executor + DB (VALID for local)
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db

      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"

      # Allow imports like: from src.utils import ...
      PYTHONPATH: /opt/airflow

      # Python deps required by DAGs
      _PIP_ADDITIONAL_REQUIREMENTS: >
        PyYAML
        requests
        beautifulsoup4
        ratelimit

    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./config:/opt/airflow/config
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs

    ports:
      - "8080:8080"

    command: >
      bash -c "
      airflow db migrate &&
      airflow users create
        --username admin
        --password admin
        --firstname Admin
        --lastname User
        --role Admin
        --email admin@example.com || true &&
      airflow scheduler &
      airflow webserver
      "


  streamlit:
    build: ./streamlit_analytics
    container_name: website_analytics_streamlit
    restart: always

    volumes:
      - ./data:/data   # shared metrics (summary.json)

    ports:
      - "8501:8501"

    depends_on:
      - airflow

